{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import keras.preprocessing.sequence as S\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense\n",
    " \n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "query_max_len = 5\n",
    "doc_max_len = 1600\n",
    "batch_size = 512\n",
    "vocab_size = 133165\n",
    "INIT_LR = 1e-2\n",
    "EPOCHS = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = Tokenizer(num_words=vocab_size)\n",
    "        self.stop_words = []\n",
    "        self.model = None\n",
    " \n",
    "    def load_cuted_corpus(self, dir, input):\n",
    "        #f = open(dir + '/' + input , 'r')\n",
    "        data = pd.read_csv(dir + '/' + input, header=None)\n",
    "        data = np.array(data)\n",
    "        idxs = list(range(len(data)))\n",
    "        np.random.shuffle(idxs)\n",
    "#         lines = f.readlines()\n",
    "        query_texts = []\n",
    "        doc_texts = []\n",
    "        labels = []\n",
    "        for i in idxs:\n",
    "            fields = data[i]\n",
    "            rate = int(fields[3])\n",
    "            cont_1 = fields[1]\n",
    "            cont_2 = fields[2]\n",
    "            cont_1 = \" \".join(cont_1)\n",
    "            cont_2 = \" \".join(cont_2)\n",
    "            query_texts.append(cont_1)\n",
    "            doc_texts.append(cont_2)\n",
    "            labels.append(rate)\n",
    " \n",
    "        self.tokenizer.fit_on_texts(query_texts)\n",
    "        self.tokenizer.fit_on_texts(doc_texts)\n",
    "#         f.close()\n",
    "        return query_texts, doc_texts, labels\n",
    " \n",
    "    def load_data(self):\n",
    "        x_1, x_2, y = self.load_cuted_corpus('corpus', 'data.csv')\n",
    "        x_1 = self.tokenizer.texts_to_sequences(x_1)\n",
    "        x_2 = self.tokenizer.texts_to_sequences(x_2)\n",
    "        x_1 = S.pad_sequences(x_1,maxlen=query_max_len)\n",
    "        x_2 = S.pad_sequences(x_2,maxlen=doc_max_len)\n",
    "        y = to_categorical(y,num_classes=2)\n",
    "        return ((x_1[0:55000], x_2[0:55000], y[0:55000]), (x_1[55000:], x_2[55000:], y[55000:]))\n",
    " \n",
    "    def train(self):\n",
    "        print('building model ...')\n",
    "        self.model = SentimentLSTM.build_model()\n",
    " \n",
    "        print('loading data ...')\n",
    "        (query_train, doc_train, rate_train), (query_test, doc_test, rate_test) = self.load_data()\n",
    " \n",
    "        print('training model ...')\n",
    "        history = self.model.fit([query_train,doc_train], rate_train, batch_size=batch_size, epochs=EPOCHS)\n",
    "        #self.model.save('model/keras.model')\n",
    "        score = self.model.evaluate([query_test,doc_test],rate_test)\n",
    "        print(score)\n",
    "        print(SentimentLSTM.draw_acc_loss(history))\n",
    " \n",
    "    def load_trained_model(self,path):\n",
    "        model = SentimentLSTM.build_model()\n",
    "        model.load_weights(path)\n",
    "        return model\n",
    "    \n",
    "    def draw_acc_loss(history):\n",
    "        acc = history.history['accuracy']\n",
    "        loss = history.history['loss']\n",
    "        epochs = range(1, len(acc) + 1)\n",
    "        plt.title('Accuracy and Loss')\n",
    "        plt.plot(epochs, acc, 'red', label='Training acc')\n",
    "        plt.plot(epochs, loss, 'blue', label='Validation loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    " \n",
    "    @staticmethod\n",
    "    def build_model():\n",
    "#         model = Sequential()\n",
    "#         model.add(Embedding(vocab_size, 256, input_length=sentence_max_len))\n",
    "#         model.add(Bidirectional(LSTM(128,implementation=2)))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(2, activation='relu'))\n",
    "#         model.compile('RMSprop', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "        query_input = keras.Input(shape=(None,), name=\"query\")\n",
    "        doc_input = keras.Input(shape=(None,), name=\"doc\")\n",
    "        query_features = Embedding(vocab_size, 32)(query_input)\n",
    "        doc_features = Embedding(vocab_size, 64)(doc_input)\n",
    "        query_features = Bidirectional(LSTM(64))(query_features)\n",
    "        doc_features = Bidirectional(LSTM(128))(doc_features)\n",
    "        merged = keras.layers.concatenate([query_features, doc_features])\n",
    "        merged = Dense(128, activation='relu')(merged)\n",
    "        merged = Dense(64, activation='relu')(merged)\n",
    "        p = Dense(2, activation='sigmoid')(merged)\n",
    "        \n",
    "        model = Model([query_input, doc_input], p)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS), metrics=['accuracy'])\n",
    "#         model.compile(loss='binary_crossentropy', optimizer=Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS), metrics=[f1])\n",
    "        print(model.summary())\n",
    "        \n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model ...\n",
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "query (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "doc (InputLayer)                [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 32)     4261280     query[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 64)     8522560     doc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 128)          49664       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 256)          197632      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 384)          0           bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          49280       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           8256        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            130         dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,088,802\n",
      "Trainable params: 13,088,802\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "loading data ...\n",
      "training model ...\n",
      "Epoch 1/60\n",
      "108/108 [==============================] - 68s 633ms/step - loss: 0.6920 - accuracy: 0.5157\n",
      "Epoch 2/60\n",
      "108/108 [==============================] - 68s 629ms/step - loss: 0.6886 - accuracy: 0.5236\n",
      "Epoch 3/60\n",
      "108/108 [==============================] - 68s 630ms/step - loss: 0.6880 - accuracy: 0.5250\n",
      "Epoch 4/60\n",
      "108/108 [==============================] - 68s 632ms/step - loss: 0.6875 - accuracy: 0.5230\n",
      "Epoch 5/60\n",
      "108/108 [==============================] - 69s 635ms/step - loss: 0.6875 - accuracy: 0.5253\n",
      "Epoch 6/60\n",
      "108/108 [==============================] - 68s 634ms/step - loss: 0.6862 - accuracy: 0.5283\n",
      "Epoch 7/60\n",
      "108/108 [==============================] - 69s 635ms/step - loss: 0.6857 - accuracy: 0.5311\n",
      "Epoch 8/60\n",
      "108/108 [==============================] - 69s 638ms/step - loss: 0.6842 - accuracy: 0.5345\n",
      "Epoch 9/60\n",
      "108/108 [==============================] - 69s 639ms/step - loss: 0.6825 - accuracy: 0.5388\n",
      "Epoch 10/60\n",
      "108/108 [==============================] - 69s 640ms/step - loss: 0.6808 - accuracy: 0.5440\n",
      "Epoch 11/60\n",
      "108/108 [==============================] - 69s 636ms/step - loss: 0.6784 - accuracy: 0.5487\n",
      "Epoch 12/60\n",
      "108/108 [==============================] - 69s 639ms/step - loss: 0.6760 - accuracy: 0.5544\n",
      "Epoch 13/60\n",
      "108/108 [==============================] - 69s 637ms/step - loss: 0.6738 - accuracy: 0.5581\n",
      "Epoch 14/60\n",
      "108/108 [==============================] - 68s 634ms/step - loss: 0.6721 - accuracy: 0.5612\n",
      "Epoch 15/60\n",
      "108/108 [==============================] - 69s 637ms/step - loss: 0.6703 - accuracy: 0.5642\n",
      "Epoch 16/60\n",
      "108/108 [==============================] - 69s 636ms/step - loss: 0.6680 - accuracy: 0.5684\n",
      "Epoch 17/60\n",
      "108/108 [==============================] - 68s 629ms/step - loss: 0.6663 - accuracy: 0.5717\n",
      "Epoch 18/60\n",
      "108/108 [==============================] - 68s 634ms/step - loss: 0.6630 - accuracy: 0.5790\n",
      "Epoch 19/60\n",
      "108/108 [==============================] - 69s 636ms/step - loss: 0.6614 - accuracy: 0.5835\n",
      "Epoch 20/60\n",
      "108/108 [==============================] - 69s 638ms/step - loss: 0.6592 - accuracy: 0.5857\n",
      "Epoch 21/60\n",
      "108/108 [==============================] - 70s 645ms/step - loss: 0.6580 - accuracy: 0.5888\n",
      "Epoch 22/60\n",
      "108/108 [==============================] - 70s 651ms/step - loss: 0.6542 - accuracy: 0.5948\n",
      "Epoch 23/60\n",
      "108/108 [==============================] - 70s 652ms/step - loss: 0.6496 - accuracy: 0.5999\n",
      "Epoch 24/60\n",
      "108/108 [==============================] - 71s 656ms/step - loss: 0.6453 - accuracy: 0.6048\n",
      "Epoch 25/60\n",
      "108/108 [==============================] - 71s 654ms/step - loss: 0.6409 - accuracy: 0.6110\n",
      "Epoch 26/60\n",
      "108/108 [==============================] - 70s 653ms/step - loss: 0.6384 - accuracy: 0.6155\n",
      "Epoch 27/60\n",
      "108/108 [==============================] - 70s 651ms/step - loss: 0.6336 - accuracy: 0.6228\n",
      "Epoch 28/60\n",
      "108/108 [==============================] - 70s 647ms/step - loss: 0.6293 - accuracy: 0.6266\n",
      "Epoch 29/60\n",
      "108/108 [==============================] - 70s 646ms/step - loss: 0.6255 - accuracy: 0.6329\n",
      "Epoch 30/60\n",
      "108/108 [==============================] - 70s 648ms/step - loss: 0.6218 - accuracy: 0.6354\n",
      "Epoch 31/60\n",
      "108/108 [==============================] - 70s 650ms/step - loss: 0.6182 - accuracy: 0.6422\n",
      "Epoch 32/60\n",
      "108/108 [==============================] - 70s 650ms/step - loss: 0.6146 - accuracy: 0.6451\n",
      "Epoch 33/60\n",
      "108/108 [==============================] - 70s 650ms/step - loss: 0.6112 - accuracy: 0.6478\n",
      "Epoch 34/60\n",
      "108/108 [==============================] - 70s 652ms/step - loss: 0.6071 - accuracy: 0.6520\n",
      "Epoch 35/60\n",
      "108/108 [==============================] - 71s 654ms/step - loss: 0.6039 - accuracy: 0.6531\n",
      "Epoch 36/60\n",
      "108/108 [==============================] - 71s 654ms/step - loss: 0.5989 - accuracy: 0.6593\n",
      "Epoch 37/60\n",
      "108/108 [==============================] - 70s 652ms/step - loss: 0.5938 - accuracy: 0.6635\n",
      "Epoch 38/60\n",
      "108/108 [==============================] - 70s 651ms/step - loss: 0.5897 - accuracy: 0.6679\n",
      "Epoch 39/60\n",
      "108/108 [==============================] - 71s 654ms/step - loss: 0.5846 - accuracy: 0.6715\n",
      "Epoch 40/60\n",
      "108/108 [==============================] - 71s 657ms/step - loss: 0.5800 - accuracy: 0.6729\n",
      "Epoch 41/60\n",
      "108/108 [==============================] - 70s 650ms/step - loss: 0.5739 - accuracy: 0.6753\n",
      "Epoch 42/60\n",
      "108/108 [==============================] - 70s 652ms/step - loss: 0.5696 - accuracy: 0.6803\n",
      "Epoch 43/60\n",
      "108/108 [==============================] - 70s 652ms/step - loss: 0.5620 - accuracy: 0.6859\n",
      "Epoch 44/60\n",
      "108/108 [==============================] - 71s 657ms/step - loss: 0.5568 - accuracy: 0.6902\n",
      "Epoch 45/60\n",
      "108/108 [==============================] - 71s 655ms/step - loss: 0.5513 - accuracy: 0.6955\n",
      "Epoch 46/60\n",
      "108/108 [==============================] - 71s 660ms/step - loss: 0.5446 - accuracy: 0.6988\n",
      "Epoch 47/60\n",
      "108/108 [==============================] - 71s 656ms/step - loss: 0.5379 - accuracy: 0.7030\n",
      "Epoch 48/60\n",
      "108/108 [==============================] - 71s 657ms/step - loss: 0.5328 - accuracy: 0.7068\n",
      "Epoch 49/60\n",
      "108/108 [==============================] - 71s 657ms/step - loss: 0.5259 - accuracy: 0.7133\n",
      "Epoch 50/60\n",
      "108/108 [==============================] - 71s 659ms/step - loss: 0.5201 - accuracy: 0.7186\n",
      "Epoch 51/60\n",
      "108/108 [==============================] - 71s 657ms/step - loss: 0.5129 - accuracy: 0.7202\n",
      "Epoch 52/60\n",
      "108/108 [==============================] - 71s 653ms/step - loss: 0.5066 - accuracy: 0.7251\n",
      "Epoch 53/60\n",
      "108/108 [==============================] - 71s 657ms/step - loss: 0.5008 - accuracy: 0.7311\n",
      "Epoch 54/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 71s 660ms/step - loss: 0.4951 - accuracy: 0.7339\n",
      "Epoch 55/60\n",
      " 60/108 [===============>..............] - ETA: 31s - loss: 0.4798 - accuracy: 0.7445"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    lstm = SentimentLSTM()\n",
    "    lstm.train()\n",
    " \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
